Regular and extensive testing is of vital importance for any file
system, in order to improve its reliability, scalability, code
quality, stability, performance, etc. Therefore, a new activity
inside the WP3.4 has been created, which is focused on all the
aspects of testing. The goal of this task is to evaluate
functionality and performance of XtreemFS, by exploiting some
existing file system test suites.

Nowadays, from a software viewpoint, there are some available tools
that are mainly designed for testing local file systems, but there
are no ready-made tools available for testing Grid File Systems.
Thus, in order to test XtreemFS, either some ad-hoc tools must be
developed or some existing distributed testing tools must be
extended.

Currently, there are two main guidelines leading the tests performed
on XtreemFS: the first one is aimed at evaluating the POSIX
compliance of XtreemFS and consequently its functionality; the
second one addresses the performance evaluation by stressing
XtreemFS with a set of tests and benchmarks (in the following we
refer to such kind of tests as regression tests).

In the next subsections we will describe both such activities, the
tools used and the results obtained.

\subsection{Testing POSIX compliance of XtreemFS}
One of the goals of XtreemFS is providing a POSIX-compliant
filesystem. In order to evaluate the correctness of functionalities,
we initially evaluated some available test suites aimed at the POSIX
compliance testing. Firstly, we evaluated the "Open Posix Tests
Suite" (https://sourceforge.net/projects/posixtest/); it resulted
not very suitable for our tests, because it performs only AIO tests
but nothing else related to the file system; moreover, we
encountered some difficulties during the installation and in
particular during the execution of the tests, and for such reasons
we discarded it. A second tool that we evaluated was the NTFS-3G
suite (http://www.ntfs-3g.org), that is a test suite available for
the most important operating systems; it includes a POSIX filesystem
test environment, the Pawel Jakub Dawidek's POSIX filesystem test
suite, that immediately seemed more suitable for our purposes than
the first one. For such a reason, we chose to exploit the PJD's
POSIX filesystem test suite (PJD-fstest) and to run it over
XtreemFS. The test suite is available on the Web under a BSD license
and we got it from http://www.ntfs-3g.org/pjd-fstest.html.
PJD-fstest performs almost 3700 regression tests that exhaustively
check a wide amount of different scenarios for the following system
calls:
\begin{itemize}
\item \textit{chmod}: changes the permissions of a files or directories
\item \textit{chown}: changes the owner of files or directories
\item \textit{link}: creates hard link
\item \textit{mkdir}: creates directories
\item \textit{mkfifo}: creates fifo named pipes
\item \textit{open}: opens a file
\item \textit{rename}: renames files or directories
\item \textit{rmdir}: removes directories
\item \textit{symlink}: creates symbolic links
\item \textit{truncate}: truncates files
\item \textit{unlink}: removes files
\end{itemize}

For each system call, the suite contemplates the execution of a set
of scripts. Each script performs a set of basic operations, like the
creation of a directory, the change of its access rights, the change
of its owner, etc., and for each operation it evaluates its return
value. If such a value is different than that expected, an error is
pointed out. Obviously, the scripts performing the tests for a
particular system call are composed of operations targeted for the
evaluation of the (hopefully correct) behaviour of that system call.
Our work consists in the automatic execution of the scripts and in
the evaluation of the failure events. Then, for each failure, we
need to interpret the cause of the problem and reproduce manually
the scenario (the sequence of operations) causing it. After this
step (that some time hides some difficulties) the problem is pointed
out in a bug tracker, in order to be scheduled for a solution.

\subsubsection{How to execute the tests}

After downloading the tarball of the PJD-fstest, we can simply extract its contents:

\verb"tar xvzf <package>"

The most significant contents of the tarball are:

\begin{itemize}
\item \textit{fstest.c}: the source code
of the main program. It provides an implementation of all the syscalls commented before.
\item \textit{Makefile}: the Makefile that we can use to compile the program.
\item \textit{tests}: a directory that contains one subdirectory for every syscall.
For each of this subdirectories, there is a set of scripts that conform the tests for the corresponding syscall.
\end{itemize}

Afterwards, we can compile the fstest.c file by executing \textbf{\textit{make}}.

To execute the tests, we have implemented a tool that basically
automatizes all  the process of updating, compiling, and installing
XtreemFS, running a basic scenario with one Directory Service, one
MRC and an OSD, and creating a volume and mounting it on a specific
directory.

Once this scenario is up and running, we enter the mount-point where
the volume  is mounted and execute the tests by using the command
\textbf{\textit{prove}} as follows:

\verb"sudo prove -r <path_to_pjd_suite>/tests"

The flag \textit{-r} specifies that \textit{prove} should traverse
all the directories recursively (so all the tests are executed).
Notice that we need root privileges so we also need to edit
\textit{/etc/fuse.conf} and add the following line:

\verb"user_allow_other"

This line allows non-root users to specify the option
\textit{allow\_other} (or \textit{allow\_root})  among the mounting
options of fuse.


\subsubsection{Results}

At the moment, XtreemFS does not support fifos, so mkfifo tests are being ignored.

The tests corresponding to the rest of the syscalls were executed
completely and the only errors encountered were due to the lack of
implementation of sticky bits on files and directories.

We plan to work on it in next XtreemFS versions, although it is not
a very  important feature and currently we have to spend our efforts
on other more significant issues.


\subsection{Regression Tests}
We use a set of regular file system test tools and custom made tests to automatically check the XtreemFS development version (the svn trunk) every night. This test environment can also be used to manually run these tests.

The main test script is \texttt{trunk/bin/xtfs\_test} and can be executed to run all tests automatically or to start/stop a test environment.

To start a test environment with all XtreemFS servers and clients, run

\begin{verbatim}
 > trunk/bin/xtfs_test --start
\end{verbatim}

This script will put all data and logfiles in the current working directory.

After setting up the test environement, the tests in \texttt{trunk/tests/} can be executed individually by calling the test scripts in the mounted XtreemFS volume.

\begin{verbatim}
 > python trunk/tests/01_simple_metadata.sh
\end{verbatim}

To shutdown all servers and unmount the clients after testing, execute

\begin{verbatim}
 > trunk/bin/xtfs_test --stop
\end{verbatim}

To clean up all data and logfiles use

\begin{verbatim}
 > trunk/bin/xtfs_test --clean
\end{verbatim}

If you want to run all tests automatically, run the test script in auto mode

\begin{verbatim}
 > trunk/bin/xtfs_test --autotest
\end{verbatim}
